# GitHub Actions Workflow for Scheduled Web Scraping
# This runs the scraper automatically on a schedule

name: CEC Nepal Scraper

on:
  # Run on push to main branch
  push:
    branches: [ main ]
  
  # Run on manual trigger
  workflow_dispatch:
  
  # Run on schedule (cron syntax)
  # This runs every Monday at 9:00 AM UTC
  schedule:
    - cron: '0 9 * * 1'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v4
    
    # Step 2: Set up Python
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r scraper/requirements.txt
    
    # Step 4: Run the scraper
    - name: Run scraper
      run: |
        cd scraper
        python cec_scraper.py
    
    # Step 5: Upload scraped data as artifacts
    - name: Upload scraped data
      uses: actions/upload-artifact@v4
      with:
        name: scraped-data-${{ github.run_number }}
        path: |
          scraper/*.json
          scraper/*.csv
        retention-days: 30
    
    # Step 6: Commit and push data back to repo (optional)
    - name: Commit and push data
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add scraper/*.json scraper/*.csv || true
        git diff --staged --quiet || git commit -m "Update scraped data [skip ci]"
        git push || true
